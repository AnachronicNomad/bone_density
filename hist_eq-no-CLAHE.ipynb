{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 16)\n",
    "\n",
    "FILENAME = 'images/annotated_raw/9.jpg'\n",
    "FNAME_ANNOTATED = 'images/annotated_colors/9-colored.png'\n",
    "# OFILE = ODIR + FNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read grayscale image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6fbeeb6b2b0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bones/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2715\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bones/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bones/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bones/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    695\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    696\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 697\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read grayscale image, \n",
    "img = cv2.imread(FILENAME, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter To Drop Shadows, Pre-Process Bone Isolation**\n",
    "\n",
    "* May want to use additional histogram based approaches here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate all image values below threshold\n",
    "ret,truncd = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "\n",
    "# Take 5x5 pixel normalized average across image\n",
    "blur = cv2.GaussianBlur(truncd,(5,5),0)\n",
    "\n",
    "# Apply binary threshold, Otsu threshold\n",
    "ret3,otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Filter morphology - close gaps\n",
    "kernel = np.ones((7,7),np.uint8)\n",
    "closing = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Recursive convex hull to identify bone in image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Contour to find bone region\n",
    "ret4 = closing.copy()\n",
    "contours, hierarchy = cv2.findContours(ret4,                                       \n",
    "                                       cv2.RETR_EXTERNAL,\n",
    "                                       cv2.CHAIN_APPROX_TC89_L1)\n",
    "\n",
    "\n",
    "                                       \n",
    "areas = [cv2.contourArea(c) for c in contours]\n",
    "max_index = np.argmax(areas)\n",
    "print(max_index)\n",
    "\n",
    "color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "tmp2 = color_img.copy() ## Save a copy, `drawContours` will mess with the image\n",
    "\n",
    "out = cv2.drawContours(color_img, contours, max_index, (0,255,0), 3)\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isolate bone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone = contours[max_index]\n",
    "\n",
    "fill_color = [0,0,0]\n",
    "mask_value = 255\n",
    "\n",
    "stencil = np.zeros(tmp2.shape[:-1]).astype(np.uint8)\n",
    "cv2.fillPoly(stencil, [bone], mask_value)\n",
    "\n",
    "sel = (stencil != mask_value)\n",
    "tmp2[sel] = fill_color\n",
    "\n",
    "BASE_IMG = cv2.cvtColor(tmp2, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(BASE_IMG, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(OFILE, BASE_IMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Color Quantization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 4 colors to represent five categories of mineralized bone or lack thereof we may find in an image.  \n",
    "\n",
    "We must assume that these five categories will exist in any \n",
    "\n",
    "1. Pitch Black `0` - no bone in this pixel\n",
    "\n",
    "...\n",
    "\n",
    "8. ?\n",
    "\n",
    "We proceed to take the array of grayscale values in the image, and categorize all pixels of the image using $k$-means clustering.  This is done using 10-fold cross-validation and initially random pixels representing grayscale values for each of the NN categories (centers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = BASE_IMG.copy()\n",
    "Z = img.reshape((-1,2))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,\n",
    "            4096, 1E-5)\n",
    "K = 10\n",
    "ret,label,center=cv2.kmeans(Z,K,None,criteria,20,\n",
    "                            cv2.KMEANS_RANDOM_CENTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Stuff A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the clusters identified and reform it into an image with consistent grayscale values.  In the printout below this cell, you can observe a listing of the lower and upper estimates for the grayscale value associated with a cluster, followed by an image colored in with the adjusted (consistent) values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the estimates for the centroids; \n",
    "# the estimate for the grayscale value for that cluster\n",
    "print(np.uint16(center))\n",
    "\n",
    "# We want to floor & reassign the midpoints of the estimates\n",
    "# to be the centroids proper.  This avoids rounding issues\n",
    "# when using the lower/upper estimates\n",
    "for i in range(0,len(center)):\n",
    "    a = center[i]\n",
    "    b = (a[0] + a[1]) / 2\n",
    "    center[i] = np.array([b, b])\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "# This is done for demonstration/viz purposes, we will not \n",
    "# be able to directly use these values\n",
    "center_conv = np.uint8(center)\n",
    "res = center_conv[label.flatten()]\n",
    "res2 = res.reshape((img.shape))\n",
    "\n",
    "plt.imshow(res2, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lamellar Area Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportion Estimation (Lamellar / Non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, what makes more sense now, is that we know clusters near the \"middle\" of the histogram have an \"average\" mineralization content -- and therefore may be lamellar.  This means that given 7 clusters, minus the \"black\"/\"empty\" bucket (for a total of 6 clusters), the middle buckets may be lamellar and the futher from the mean, the outer buckets are probably non-lamellar**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the grayscale values sorted, in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = res2.copy()\n",
    "category_grayscale_values = np.sort(np.unique(tmp1.flatten()))\n",
    "category_grayscale_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead, I keep everything in the middle buckets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = res2.copy()\n",
    "\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[0])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[1])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[2])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[3])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[4])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[5])] = [0]\n",
    "#tmp1[np.where(tmp1 == category_grayscale_values[6])] = [0]\n",
    "#tmp1[np.where(tmp1 == category_grayscale_values[7])] = [0]\n",
    "#tmp1[np.where(tmp1 == category_grayscale_values[8])] = [0]\n",
    "tmp1[np.where(tmp1 == category_grayscale_values[9])] = [0]\n",
    "\n",
    "\n",
    "plt.imshow(tmp1, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to get the proportional area out of the original identified bone (the convex hull/contour step with green outline).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#area_identified_bone = areas[np.argmax(areas)]\n",
    "#print(area_identified_bone)\n",
    "\n",
    "area_identified_bone = cv2.countNonZero(res2)\n",
    "area_identified_bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_lamellar_est = cv2.countNonZero(tmp1)\n",
    "area_lamellar_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_est = area_lamellar_est / area_identified_bone\n",
    "proportion_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare to the annotation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read annotated red/blue image, \n",
    "annotated_img = cv2.imread(FNAME_ANNOTATED)\n",
    "annotated_img = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "color_dict_HSV = {'black': [[180, 255, 30], [0, 0, 0]],\n",
    "              'white': [[180, 18, 255], [0, 0, 231]],\n",
    "              'red1': [[180, 255, 255], [159, 50, 70]],\n",
    "              'red2': [[9, 255, 255], [0, 50, 70]],\n",
    "              'green': [[89, 255, 255], [36, 50, 70]],\n",
    "              'blue': [[128, 255, 255], [90, 50, 70]],\n",
    "              'yellow': [[35, 255, 255], [25, 50, 70]],\n",
    "              'purple': [[158, 255, 255], [129, 50, 70]],\n",
    "              'orange': [[24, 255, 255], [10, 50, 70]],\n",
    "              'gray': [[180, 18, 230], [0, 0, 40]]}\n",
    "\n",
    "plt.imshow(annotated_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Red (Non-Lamellar) Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify BLUE (lamellar) using HSV colorspace\n",
    "img_hsv = annotated_img.copy()\n",
    "\n",
    "# lower mask (0-10)\n",
    "lower_red = np.array([0,50,50])\n",
    "upper_red = np.array([10,255,255])\n",
    "mask0 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "# upper mask (170-180)\n",
    "lower_red = np.array([170,50,50])\n",
    "upper_red = np.array([180,255,255])\n",
    "mask1 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "# join masks for lower and upper bound of red values\n",
    "mask = mask0+mask1\n",
    "\n",
    "# Set everything else to zero\n",
    "output_hsv = img_hsv.copy()\n",
    "output_hsv[np.where(mask==0)] = 0\n",
    "\n",
    "r = cv2.cvtColor(output_hsv, cv2.COLOR_HSV2RGB)\n",
    "r = cv2.cvtColor(output_hsv, cv2.COLOR_RGB2GRAY)\n",
    "red_area = cv2.countNonZero(r)\n",
    "print(red_area)\n",
    "\n",
    "plt.imshow(r, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Blue (Lamellar) Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify RED (non-lamellar) using HSV colorspace\n",
    "img_hsv = annotated_img.copy()\n",
    "\n",
    "# lower mask (0-10)\n",
    "lower_blue = np.array(color_dict_HSV['blue'][1])\n",
    "upper_blue = np.array(color_dict_HSV['blue'][0])\n",
    "mask = cv2.inRange(img_hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Set everything else to zero\n",
    "output_hsv = img_hsv.copy()\n",
    "output_hsv[np.where(mask==0)] = 0\n",
    "\n",
    "b = cv2.cvtColor(output_hsv, cv2.COLOR_HSV2RGB)\n",
    "b = cv2.cvtColor(output_hsv, cv2.COLOR_RGB2GRAY)\n",
    "blue_area = cv2.countNonZero(b)\n",
    "print(blue_area)\n",
    "\n",
    "plt.imshow(b, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the Annotated Proportion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_prop = blue_area / (blue_area + red_area)\n",
    "annotated_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's the difference in proportion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_est - annotated_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
